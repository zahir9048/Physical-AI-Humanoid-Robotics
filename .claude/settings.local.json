{
  "permissions": {
    "allow": [
      "Bash(git fetch:*)",
      "Bash(ls:*)",
      "Bash(.specify/scripts/bash/setup-plan.sh:*)",
      "Bash(.specify/scripts/bash/check-prerequisites.sh:*)",
      "Bash(npx create-docusaurus@latest:*)",
      "Bash(npm install)",
      "Bash(find docs/ -name \"*.mdx\" -exec basename {} ;)",
      "Bash(npm run start)",
      "Bash(npx docusaurus start --port 3001)",
      "Bash(npm install @easyops-cn/docusaurus-search-local)",
      "WebSearch",
      "Bash(npm run write-translations)",
      "Bash(.specify/scripts/bash/create-new-feature.sh --json \"Build an integrated RAG (Retrieval-Augmented Generation) chatbot for the Physical AI & Humanoid Robotics textbook. The chatbot should be embedded within the Docusaurus book and provide intelligent Q&A capabilities.\n\nCORE FUNCTIONALITY:\n\n1. Chatbot Interface:\n- Embedded chat widget in the Docusaurus site (floating button or sidebar)\n- Clean, modern UI with message history\n- Support for both typing and voice input\n- Real-time streaming responses\n- Markdown rendering for code examples and formatting\n- Copy code functionality for responses containing code\n- Clear conversation history option\n\n2. RAG Capabilities:\n- Answer questions about book content using context from the textbook\n- Text selection feature: Users can highlight/select text on any page and ask questions specifically about that selection\n- General queries: Answer questions about the entire book content\n- Context-aware responses that reference specific chapters/sections\n- Code example generation related to ROS 2, Gazebo, Isaac, etc.\n\n3. Query Types to Support:\n- \"\"Explain this concept\"\" (with or without text selection)\n- \"\"Show me code example for [topic]\"\"\n- \"\"What hardware do I need for [module]?\"\"\n- \"\"How do I set up [tool/environment]?\"\"\n- \"\"Compare [concept A] vs [concept B]\"\"\n- \"\"Find information about [topic] in the book\"\"\n\nUSER INTERACTION FLOWS:\n\nFlow 1 - General Question:\n1. User opens chatbot interface\n2. User types or speaks question\n3. System retrieves relevant chunks from vector database\n4. OpenAI Agent generates contextual response\n5. Response displayed with source references (chapter/section)\n\nFlow 2 - Text Selection Query:\n1. User highlights text on any page (e.g., a paragraph about ROS 2 nodes)\n2. User clicks \"\"Ask about this\"\" button or opens chatbot\n3. Selected text is automatically included as context\n4. User asks specific question about the selection\n5. System provides focused answer based on selected text + related content\n\nFlow 3 - Follow-up Questions:\n1. User asks initial question\n2. System responds with context\n3. User asks follow-up without re-explaining context\n4. System maintains conversation history for coherent dialogue\n\nTECHNICAL REQUIREMENTS:\n\nBackend Components:\n1. FastAPI application serving the chatbot API\n2. OpenAI Agents SDK for conversational intelligence\n3. Qdrant Cloud (Free Tier) for vector storage\n4. Neon Serverless Postgres for:\n   - User conversation history\n   - Query logs and analytics\n   - User feedback on responses\n5. Document processing pipeline to chunk and embed textbook content\n\nFrontend Components:\n1. React-based chat widget embedded in Docusaurus\n2. Integration with Docusaurus theme\n3. Text selection handler for page content\n4. Voice input capability (Web Speech API)\n5. Responsive design for mobile and desktop\n\nData Pipeline:\n1. Extract all textbook content (MDX files)\n2. Chunk content intelligently (by section/topic)\n3. Generate embeddings using OpenAI embeddings\n4. Store in Qdrant with metadata (chapter, section, URL)\n5. Index for fast retrieval\n\nRAG Implementation:\n1. User query â†’ Embedding generation\n2. Semantic search in Qdrant (top-k relevant chunks)\n3. Context assembly (chunks + selected text if any)\n4. OpenAI Agent with system prompt for Physical AI domain\n5. Streaming response back to frontend\n\nFEATURES TO IMPLEMENT:\n\nEssential Features:\n- Real-time chat interface\n- Vector-based semantic search\n- Context-aware responses with citations\n- Text selection Q&A capability\n- Conversation history persistence\n- Code syntax highlighting in responses\n\nEnhanced Features:\n- Voice input/output\n- Multi-turn conversations with context\n- Source attribution (link to specific book sections)\n- Feedback mechanism (thumbs up/down)\n- Query analytics dashboard (admin)\n- Rate limiting and authentication (if needed)\n\nINTEGRATION WITH DOCUSAURUS:\n\n1. Chatbot Widget:\n- Floating button in bottom-right corner\n- Expandable chat window (400x600px)\n- Closeable/minimizable\n- Persist state across page navigation\n\n2. Text Selection Integration:\n- Custom event listener on all markdown content\n- \"\"Ask AI\"\" tooltip appears on text selection\n- Passes selected text + page URL to chatbot\n\n3. Styling:\n- Match Docusaurus theme colors\n- Support dark/light mode switching\n- Smooth animations and transitions\n- Mobile-responsive design\n\nDEPLOYMENT REQUIREMENTS:\n\n1. Backend Deployment:\n- Containerized FastAPI app (Docker)\n- Deploy to cloud platform (Vercel, Railway, or Render)\n- Environment variables for API keys\n- CORS configuration for Docusaurus frontend\n\n2. Database Setup:\n- Neon Postgres database (free tier)\n- Qdrant Cloud collection (free tier)\n- Database migrations for schema\n\n3. CI/CD:\n- GitHub Actions for automated deployment\n- Separate staging and production environments\n- Automated testing before deployment\n\nSECURITY & PERFORMANCE:\n\n1. Security:\n- API rate limiting\n- Input validation and sanitization\n- Secure API key management\n- CORS properly configured\n\n2. Performance:\n- Response caching for common queries\n- Efficient vector search with filters\n- Streaming responses for better UX\n- Lazy loading of chat widget\n\n3. Monitoring:\n- Query response times\n- Error tracking\n- User engagement metrics\n- Token usage monitoring\n\nDATA REQUIREMENTS:\n\n1. Vector Database (Qdrant):\n- Collection: \"\"physical-ai-textbook\"\"\n- Vector dimension: 1536 (OpenAI ada-002)\n- Metadata: chapter, section, title, url, content\n\n2. Postgres Schema:\n- conversations table (id, user_id, created_at)\n- messages table (id, conversation_id, role, content, timestamp)\n- feedback table (id, message_id, rating, comment)\n\nACCEPTANCE CRITERIA:\n\n1. User can open chatbot from any page\n2. User can ask questions and get relevant answers from book content\n3. User can select text and ask specific questions about it\n4. Responses include citations/references to book sections\n5. Conversation history is maintained during session\n6. Code examples in responses are properly formatted\n7. Chatbot matches Docusaurus theme styling\n8. Mobile-responsive interface\n9. Backend API properly handles errors\n10. All components deployed and accessible\n\nCONSTRAINTS:\n\n1. Use OpenAI Agents SDK (not direct API calls)\n2. Must use Qdrant Cloud Free Tier (limit: 1GB)\n3. Must use Neon Serverless Postgres Free Tier\n4. Chatbot must not interfere with book navigation/reading\n5. Initial page load should not be slowed by chatbot\n6. Text selection feature should work on all book pages\" --number 2 --short-name \"rag-chatbot\")",
      "Bash(if [ -d \"/home/zahir/physical-ai-textbook/specs/002-rag-chatbot/checklists\" ])",
      "Bash(then)",
      "Bash(else)",
      "Bash(fi)",
      "Bash(python scripts/setup_postgres.py)",
      "Bash(python3 scripts/setup_postgres.py)",
      "Bash(pip3 install -r backend/requirements.txt)",
      "Bash(python3 -m pip --version)",
      "Bash(sudo apt update)",
      "Bash(sudo apt install:*)",
      "Bash(python3 -m pip install -r backend/requirements.txt)",
      "Bash(source venv/bin/activate)",
      "Bash(pip install fastapi uvicorn python-dotenv pydantic pydantic-settings)",
      "Bash(pip install openai qdrant-client)",
      "Bash(source ../venv/bin/activate)",
      "Bash(python -c \"from src.core.config import settings; print(''Config loaded successfully'')\")",
      "Bash(pip install \"pydantic-settings==2.6.1\")",
      "Bash(pip install \"pydantic-settings==2.6.1\" --force-reinstall)"
    ],
    "deny": [],
    "ask": []
  }
}
