"use strict";(globalThis.webpackChunkphysical_ai_textbook=globalThis.webpackChunkphysical_ai_textbook||[]).push([[757],{599:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>h,frontMatter:()=>r,metadata:()=>i,toc:()=>d});const i=JSON.parse('{"id":"glossary","title":"Glossary of Robotics and AI Terms","description":"This glossary provides definitions for key terms used throughout the Physical AI & Humanoid Robotics textbook.","source":"@site/docs/glossary.mdx","sourceDirName":".","slug":"/glossary","permalink":"/physical-ai-textbook/docs/glossary","draft":false,"unlisted":false,"editUrl":"https://github.com/zahir9048/physical-ai-textbook/tree/001-build-comprehensive-textbook/docs/glossary.mdx","tags":[],"version":"current","frontMatter":{"sidebar_label":"Glossary"},"sidebar":"tutorialSidebar","previous":{"title":"Prerequisites and Setup","permalink":"/physical-ai-textbook/docs/prerequisites-setup"},"next":{"title":"Additional Resources","permalink":"/physical-ai-textbook/docs/additional-resources"}}');var o=s(4848),t=s(8453);const r={sidebar_label:"Glossary"},a="Glossary of Robotics and AI Terms",l={},d=[{value:"A",id:"a",level:2},{value:"B",id:"b",level:2},{value:"C",id:"c",level:2},{value:"D",id:"d",level:2},{value:"E",id:"e",level:2},{value:"F",id:"f",level:2},{value:"G",id:"g",level:2},{value:"H",id:"h",level:2},{value:"I",id:"i",level:2},{value:"J",id:"j",level:2},{value:"K",id:"k",level:2},{value:"L",id:"l",level:2},{value:"M",id:"m",level:2},{value:"N",id:"n",level:2},{value:"O",id:"o",level:2},{value:"P",id:"p",level:2},{value:"R",id:"r",level:2},{value:"S",id:"s",level:2},{value:"T",id:"t",level:2},{value:"U",id:"u",level:2},{value:"V",id:"v",level:2},{value:"W",id:"w",level:2},{value:"Z",id:"z",level:2}];function c(e){const n={h1:"h1",h2:"h2",header:"header",p:"p",strong:"strong",...(0,t.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.header,{children:(0,o.jsx)(n.h1,{id:"glossary-of-robotics-and-ai-terms",children:"Glossary of Robotics and AI Terms"})}),"\n",(0,o.jsx)(n.p,{children:"This glossary provides definitions for key terms used throughout the Physical AI & Humanoid Robotics textbook."}),"\n",(0,o.jsx)(n.h2,{id:"a",children:"A"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Action"}),": In ROS 2, a communication pattern for long-running tasks that provide feedback and can be canceled."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Admittance Control"}),": A control strategy where the robot's motion is controlled based on applied forces, the inverse of impedance control."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Algolia DocSearch"}),": A search solution commonly used in documentation sites to provide fast, relevant search results."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Artificial Intelligence (AI)"}),": The simulation of human intelligence processes by machines, especially computer systems."]}),"\n",(0,o.jsx)(n.h2,{id:"b",children:"B"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Bipedal Locomotion"}),": The ability of a robot with two legs to walk or move in a stable manner."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Bullet Physics"}),": An open-source physics engine used for simulating rigid body dynamics."]}),"\n",(0,o.jsx)(n.h2,{id:"c",children:"C"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Capture Point (CP)"}),": A point used in bipedal robotics to determine where a robot needs to step to regain balance."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Code Examples"}),": Detailed, runnable code snippets demonstrating concepts and techniques."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Cognitive Planning"}),": High-level decision-making processes that enable robots to plan and execute complex tasks."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Computer Vision"}),": A field of AI that enables computers to interpret and understand visual information from the world."]}),"\n",(0,o.jsx)(n.h2,{id:"d",children:"D"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Dexterity"}),": The ability of a robotic system to perform fine manipulation tasks with precision."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Dynamics"}),": The study of forces and torques that cause motion in mechanical systems."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Docusaurus"}),": A static site generator for building documentation websites, used for this textbook."]}),"\n",(0,o.jsx)(n.h2,{id:"e",children:"E"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Embodied Intelligence"}),": Intelligence that emerges from the interaction between an agent and its physical environment."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"End-Effector"}),": The tool or device at the end of a robotic arm that interacts with the environment."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"External Links"}),": References to resources outside the textbook, such as online tutorials or documentation."]}),"\n",(0,o.jsx)(n.h2,{id:"f",children:"F"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Forward Kinematics"}),": The process of determining the position and orientation of the end-effector based on joint angles."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Force Control"}),": A control strategy that regulates the forces applied by a robot to its environment."]}),"\n",(0,o.jsx)(n.h2,{id:"g",children:"G"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Gazebo"}),": A 3D simulation environment for robotics that provides physics simulation and sensor models."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Generative AI"}),": AI systems that can create new content, such as text, images, or other data."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Grasping"}),": The ability of a robot to securely hold and manipulate objects."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Gripper"}),": A device at the end of a robotic arm designed to grasp and hold objects."]}),"\n",(0,o.jsx)(n.h2,{id:"h",children:"H"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Hardware Requirements"}),": Specifications for computational and physical components needed for robotics applications."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Human-Robot Interaction (HRI)"}),": The study of interactions between humans and robots."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Humanoid Robot"}),": A robot with a human-like body structure, typically featuring a head, torso, arms, and legs."]}),"\n",(0,o.jsx)(n.h2,{id:"i",children:"I"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Impedance Control"}),": A control strategy that regulates the relationship between forces applied to a robot and its motion."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Inverse Kinematics"}),": The process of determining joint angles required to achieve a desired end-effector position."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Isaac SDK"}),": NVIDIA's robotics software development kit for developing and deploying AI-based applications."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Isaac Sim"}),": NVIDIA's robotics simulation environment built on the Omniverse platform."]}),"\n",(0,o.jsx)(n.h2,{id:"j",children:"J"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Joint Space"}),": The space defined by the joint angles of a robotic system."]}),"\n",(0,o.jsx)(n.h2,{id:"k",children:"K"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Kinematics"}),": The study of motion without considering the forces that cause it."]}),"\n",(0,o.jsx)(n.h2,{id:"l",children:"L"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Large Language Model (LLM)"}),": Advanced AI models capable of understanding and generating human-like text."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Learning Objectives"}),": Clear statements that define what students should be able to do after completing a section."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"LiDAR"}),": Light Detection and Ranging, a remote sensing method using light in the form of a pulsed laser."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Locomotion"}),": The ability of a robot to move from one place to another."]}),"\n",(0,o.jsx)(n.h2,{id:"m",children:"M"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Manipulation"}),": The ability of a robot to interact with objects in its environment."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Mermaid"}),": A diagramming and charting tool that uses markdown-inspired text definitions to render and modify diagrams dynamically."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Motion Planning"}),": The computational problem of finding a sequence of movements for a robot to reach a goal."]}),"\n",(0,o.jsx)(n.h2,{id:"n",children:"N"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Natural Language Understanding (NLU)"}),": A subfield of AI focused on enabling machines to understand and interpret human language."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Navigation"}),": The ability of a robot to move through its environment while avoiding obstacles."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Node"}),": In ROS, a process that performs computation. Multiple nodes communicate via topics, services, and actions."]}),"\n",(0,o.jsx)(n.h2,{id:"o",children:"O"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Omniverse Kit"}),": NVIDIA's platform for 3D design collaboration and world simulation."]}),"\n",(0,o.jsx)(n.h2,{id:"p",children:"P"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Path Planning"}),": The process of determining a route for a robot to follow from start to goal."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Perception"}),": The ability of a robot to interpret sensory information from its environment."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Physics Simulation"}),": Computer modeling of real-world physics to simulate interactions between objects."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Practical Exercises"}),": Hands-on tasks that allow students to apply concepts learned in the textbook."]}),"\n",(0,o.jsx)(n.h2,{id:"r",children:"R"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Real-time"}),": Systems that must respond to inputs within a guaranteed time frame."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Reinforcement Learning (RL)"}),": A type of machine learning where agents learn to make decisions by receiving rewards."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"ROS 2 (Robot Operating System 2)"}),": A flexible framework for writing robot software, providing hardware abstraction and communication."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Rviz2"}),": The 3D visualization tool for ROS 2."]}),"\n",(0,o.jsx)(n.h2,{id:"s",children:"S"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Sensor Fusion"}),": The process of combining data from multiple sensors to achieve better accuracy and reliability."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Sim-to-Real Transfer"}),": The process of transferring skills learned in simulation to real-world robots."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"SLAM (Simultaneous Localization and Mapping)"}),": The computational problem of constructing or updating a map of an unknown environment while simultaneously keeping track of an agent's location."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Speech Recognition"}),": The ability of a computer to identify and understand spoken language."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Stereo Vision"}),": The process of extracting 3D information from camera images using multiple viewpoints."]}),"\n",(0,o.jsx)(n.h2,{id:"t",children:"T"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Topic"}),": In ROS, a publish-subscribe communication pattern for streaming data between nodes."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Trajectory Optimization"}),": The process of finding the optimal path for a robot to follow."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"TensorRT"}),": NVIDIA's inference optimizer and runtime for deep learning models."]}),"\n",(0,o.jsx)(n.h2,{id:"u",children:"U"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"URDF (Unified Robot Description Format)"}),": An XML format for representing robot models in ROS."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"USD (Universal Scene Description)"}),": NVIDIA's file format for 3D computer graphics applications."]}),"\n",(0,o.jsx)(n.h2,{id:"v",children:"V"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Visual Perception"}),": The ability of a robot to interpret and understand visual information from cameras or other visual sensors."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Voice-to-Action"}),": The process of converting spoken commands into robot actions."]}),"\n",(0,o.jsx)(n.h2,{id:"w",children:"W"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Workspace"}),": The space in which a robot can operate or manipulate objects."]}),"\n",(0,o.jsx)(n.h2,{id:"z",children:"Z"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Zero Moment Point (ZMP)"}),": A criterion used in bipedal robotics to determine the stability of a walking robot."]})]})}function h(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(c,{...e})}):c(e)}},8453:(e,n,s)=>{s.d(n,{R:()=>r,x:()=>a});var i=s(6540);const o={},t=i.createContext(o);function r(e){const n=i.useContext(t);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:r(e.components),i.createElement(t.Provider,{value:n},e.children)}}}]);