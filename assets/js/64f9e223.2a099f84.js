"use strict";(globalThis.webpackChunkphysical_ai_textbook=globalThis.webpackChunkphysical_ai_textbook||[]).push([[322],{5735:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>h,frontMatter:()=>t,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"hardware-requirements","title":"Hardware Requirements","description":"This section outlines the computational and hardware requirements for engaging with the Physical AI & Humanoid Robotics textbook. The demands vary based on the complexity of simulations, visual perception tasks, and the integration of generative AI models.","source":"@site/docs/hardware-requirements.mdx","sourceDirName":".","slug":"/hardware-requirements","permalink":"/Physical-AI-Humanoid-Robotics/docs/hardware-requirements","draft":false,"unlisted":false,"editUrl":"https://github.com/zahir9048/Physical-AI-Humanoid-Robotics/tree/001-build-comprehensive-textbook/docs/hardware-requirements.mdx","tags":[],"version":"current","frontMatter":{"sidebar_label":"Hardware Requirements"},"sidebar":"tutorialSidebar","previous":{"title":"Capstone Project","permalink":"/Physical-AI-Humanoid-Robotics/docs/module-6/capstone-project"},"next":{"title":"Prerequisites and Setup","permalink":"/Physical-AI-Humanoid-Robotics/docs/prerequisites-setup"}}');var o=i(4848),r=i(8453);const t={sidebar_label:"Hardware Requirements"},a="Hardware Requirements",l={},c=[{value:"Computational Loads",id:"computational-loads",level:2},{value:"Physics Simulation",id:"physics-simulation",level:3},{value:"Visual Perception",id:"visual-perception",level:3},{value:"Generative AI",id:"generative-ai",level:3},{value:"Tier 1: The &quot;Digital Twin&quot; Workstation",id:"tier-1-the-digital-twin-workstation",level:2},{value:"Key Components:",id:"key-components",level:3},{value:"Use Cases:",id:"use-cases",level:3},{value:"Performance Expectation:",id:"performance-expectation",level:3},{value:"Tier 2: The &quot;Physical AI&quot; Edge Kit",id:"tier-2-the-physical-ai-edge-kit",level:2},{value:"Key Components:",id:"key-components-1",level:3},{value:"Use Cases:",id:"use-cases-1",level:3},{value:"Performance Expectation:",id:"performance-expectation-1",level:3},{value:"Tier 3: The Robot Lab (Options A, B, C)",id:"tier-3-the-robot-lab-options-a-b-c",level:2},{value:"Option A: High-Performance Humanoid Robot",id:"option-a-high-performance-humanoid-robot",level:3},{value:"Option B: Advanced Manipulator Arm System",id:"option-b-advanced-manipulator-arm-system",level:3},{value:"Option C: Mobile Manipulation Platform",id:"option-c-mobile-manipulation-platform",level:3},{value:"Economy Jetson Student Kit",id:"economy-jetson-student-kit",level:2},{value:"Key Components:",id:"key-components-2",level:3},{value:"Use Cases:",id:"use-cases-2",level:3},{value:"Performance Expectation:",id:"performance-expectation-2",level:3},{value:"Cloud vs. On-Premise Options",id:"cloud-vs-on-premise-options",level:2},{value:"Cloud-Based Solutions",id:"cloud-based-solutions",level:3},{value:"On-Premise Solutions",id:"on-premise-solutions",level:3}];function d(e){const n={h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.header,{children:(0,o.jsx)(n.h1,{id:"hardware-requirements",children:"Hardware Requirements"})}),"\n",(0,o.jsx)(n.p,{children:"This section outlines the computational and hardware requirements for engaging with the Physical AI & Humanoid Robotics textbook. The demands vary based on the complexity of simulations, visual perception tasks, and the integration of generative AI models."}),"\n",(0,o.jsx)(n.h2,{id:"computational-loads",children:"Computational Loads"}),"\n",(0,o.jsx)(n.p,{children:"To effectively run the exercises, simulations, and projects in this textbook, consider the following key computational loads:"}),"\n",(0,o.jsx)(n.h3,{id:"physics-simulation",children:"Physics Simulation"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Description:"})," Simulating realistic robot dynamics, interactions with environments, and complex physical phenomena (e.g., fluid dynamics, soft bodies)."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Requirements:"})," High CPU clock speeds, significant multi-core performance, and often GPU acceleration for parallelizable physics engines (e.g., NVIDIA PhysX, Bullet)."]}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"visual-perception",children:"Visual Perception"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Description:"})," Processing sensor data from cameras (RGB, depth, stereo), LiDAR, and other visual modalities for tasks like object detection, tracking, segmentation, and SLAM."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Requirements:"})," High-performance GPUs (NVIDIA CUDA cores are highly recommended for AI/ML frameworks), ample video memory (VRAM), and fast data transfer rates."]}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"generative-ai",children:"Generative AI"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Description:"})," Running or fine-tuning large language models (LLMs) and other generative models for conversational robotics, cognitive planning, and advanced decision-making."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Requirements:"})," State-of-the-art GPUs with substantial VRAM (e.g., 24GB+), Tensor Cores (for NVIDIA GPUs) for accelerated AI inference, and high-bandwidth memory (HBM)."]}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"tier-1-the-digital-twin-workstation",children:'Tier 1: The "Digital Twin" Workstation'}),"\n",(0,o.jsx)(n.p,{children:"This tier is designed for students and researchers focusing on high-fidelity simulation and advanced AI model training in a digital environment. It provides a robust platform for developing and testing complex physical AI algorithms without the need for physical robot hardware."}),"\n",(0,o.jsx)(n.h3,{id:"key-components",children:"Key Components:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"CPU:"})," Intel Core i9 (12th Gen or newer) / AMD Ryzen 9 (5000 series or newer) with 12+ cores for parallel physics simulations and general computational tasks."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"GPU:"})," NVIDIA GeForce RTX 3080 / 4070 Ti (or equivalent AMD Radeon RX 6800 XT / 7800 XT) with 12GB+ VRAM for visual perception, GPU-accelerated physics, and AI model inference."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"RAM:"})," 32GB DDR4 (3600MHz+) / DDR5 (5200MHz+) for handling large datasets and complex simulation states."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Storage:"})," 1TB NVMe SSD for fast loading of simulation assets, operating system, and project files."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Operating System:"})," Ubuntu 22.04 LTS (recommended) for optimal compatibility with ROS 2, NVIDIA Isaac SDK, and other robotics software."]}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"use-cases",children:"Use Cases:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Developing and testing advanced robot control algorithms in simulated environments (e.g., Gazebo, Isaac Sim)."}),"\n",(0,o.jsx)(n.li,{children:"Training medium-sized deep learning models for perception and decision-making."}),"\n",(0,o.jsx)(n.li,{children:"Exploring complex physics interactions and environmental dynamics."}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"performance-expectation",children:"Performance Expectation:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Smooth real-time simulation for moderate-complexity robot models and environments."}),"\n",(0,o.jsx)(n.li,{children:"Efficient training times for common vision and RL tasks."}),"\n",(0,o.jsx)(n.li,{children:"Capable of running multiple development tools concurrently."}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"tier-2-the-physical-ai-edge-kit",children:'Tier 2: The "Physical AI" Edge Kit'}),"\n",(0,o.jsx)(n.p,{children:"This tier is designed for students and practitioners who want to bridge the gap between simulation and the real world. It focuses on deploying AI models to actual robotic hardware, emphasizing real-time inference and embedded system development."}),"\n",(0,o.jsx)(n.h3,{id:"key-components-1",children:"Key Components:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"SBC (Single Board Computer):"})," NVIDIA Jetson Orin Nano / Xavier NX / AGX Orin for on-device AI inference and sensor data processing."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Sensors:"})," Stereo cameras (e.g., Intel RealSense), LiDAR (e.g., RPLIDAR), IMUs, and force sensors for real-time environmental perception and robot state estimation."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Actuators:"})," Dynamixel servos, stepper motors, or brushless motors depending on the robot platform, controlled via dedicated motor drivers."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Power Supply:"})," Portable power bank or dedicated power solution to operate the SBC and actuators."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Software Stack:"})," ROS 2 (Humble/Iron), NVIDIA JetPack SDK, CUDA, cuDNN, TensorRT for optimized AI inference on the Jetson platform."]}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"use-cases-1",children:"Use Cases:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Deploying trained AI models to physical robots for real-world interaction."}),"\n",(0,o.jsx)(n.li,{children:"Developing embedded robotics applications with real-time constraints."}),"\n",(0,o.jsx)(n.li,{children:"Conducting experiments in sim-to-real transfer and domain adaptation."}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"performance-expectation-1",children:"Performance Expectation:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Real-time AI inference for basic perception and control tasks on the edge device."}),"\n",(0,o.jsx)(n.li,{children:"Moderate data processing capabilities for multi-sensor integration."}),"\n",(0,o.jsx)(n.li,{children:"Suitable for smaller-scale robotic experiments and rapid prototyping."}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"tier-3-the-robot-lab-options-a-b-c",children:"Tier 3: The Robot Lab (Options A, B, C)"}),"\n",(0,o.jsx)(n.p,{children:"This tier caters to advanced research and development, providing access to full-scale humanoid or complex robotic systems. It emphasizes high-performance computing for advanced AI, complex motion planning, and human-robot interaction."}),"\n",(0,o.jsx)(n.h3,{id:"option-a-high-performance-humanoid-robot",children:"Option A: High-Performance Humanoid Robot"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Robot:"})," Commercial or research-grade humanoid robot (e.g., Boston Dynamics Spot, Unitree H1, Agility Robotics Digit)."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Control System:"})," Integrated high-performance IPC (Industrial PC) or dedicated embedded controller with powerful CPU/GPU."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Sensors:"})," Advanced perception suite including high-resolution cameras, 3D LiDAR, force-torque sensors at joints, and highly accurate IMUs."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Software Stack:"})," ROS 2, custom control frameworks, real-time operating systems (RTOS), and NVIDIA Isaac ROS for accelerated perception and navigation."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Use Cases:"})," Research in bipedal locomotion, dynamic manipulation, human-robot collaboration, and complex task execution."]}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"option-b-advanced-manipulator-arm-system",children:"Option B: Advanced Manipulator Arm System"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Robot:"})," Industrial robotic arm (e.g., KUKA, Universal Robots, Franka Emika)."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Control System:"})," Manufacturer-provided controller with ROS 2 integration."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Sensors:"})," High-precision vision systems (e.g., depth cameras, photometric stereo), tactile sensors, and force-torque sensors at the wrist."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Software Stack:"})," ROS 2, MoveIt! for motion planning, and custom perception pipelines."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Use Cases:"})," Fine manipulation, assembly tasks, object recognition and grasping, and learning from demonstration."]}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"option-c-mobile-manipulation-platform",children:"Option C: Mobile Manipulation Platform"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Robot:"})," Mobile base with integrated robotic arm (e.g., Fetch Robotics Freight, Clearpath Ridgeback with UR5)."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Control System:"})," Integrated computing unit with sufficient power for navigation and manipulation."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Sensors:"})," 2D/3D LiDAR for navigation, stereo cameras for perception, and encoders for odometry."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Software Stack:"})," ROS 2, Navigation2 stack, MoveIt!, and potentially custom SLAM implementations."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Use Cases:"})," Autonomous navigation in complex environments, mobile pick-and-place, and service robotics applications."]}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"economy-jetson-student-kit",children:"Economy Jetson Student Kit"}),"\n",(0,o.jsx)(n.p,{children:"This kit provides an affordable entry point for students to get hands-on experience with Physical AI and embedded robotics. It focuses on fundamental concepts and practical application on a compact, low-power platform."}),"\n",(0,o.jsx)(n.h3,{id:"key-components-2",children:"Key Components:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"SBC (Single Board Computer):"})," NVIDIA Jetson Nano Developer Kit (2GB/4GB) or Jetson Orin Nano Developer Kit (8GB) for basic AI inference and embedded programming."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Robot Platform:"})," Small mobile robot chassis (e.g., Donkey Car, JetBot, or custom 3D-printed designs)."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Sensors:"})," USB webcam, ultrasonic sensors, basic IMU, and motor encoders."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Actuators:"})," DC motors with motor drivers."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Power Supply:"})," USB power bank or wall adapter."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Software Stack:"})," Ubuntu, ROS 2 (Foxy/Galactic), NVIDIA JetPack SDK (L4T), basic AI frameworks (e.g., TensorFlow Lite, PyTorch Mobile)."]}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"use-cases-2",children:"Use Cases:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Learning ROS 2 fundamentals on real hardware."}),"\n",(0,o.jsx)(n.li,{children:"Implementing basic navigation and obstacle avoidance."}),"\n",(0,o.jsx)(n.li,{children:"Developing simple object detection and tracking applications."}),"\n",(0,o.jsx)(n.li,{children:"Exploring embedded programming for robotics."}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"performance-expectation-2",children:"Performance Expectation:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Entry-level performance for small AI models and basic robotics tasks."}),"\n",(0,o.jsx)(n.li,{children:"Suitable for learning and experimenting with core Physical AI concepts."}),"\n",(0,o.jsx)(n.li,{children:"Limited computational resources for complex simulations or large-scale AI models."}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"cloud-vs-on-premise-options",children:"Cloud vs. On-Premise Options"}),"\n",(0,o.jsx)(n.p,{children:"The choice between cloud-based and on-premise infrastructure significantly impacts accessibility, scalability, cost, and latency for Physical AI development. This section outlines the considerations for each."}),"\n",(0,o.jsx)(n.h3,{id:"cloud-based-solutions",children:"Cloud-Based Solutions"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Description:"})," Leveraging remote data centers for computational resources, including virtual machines, GPU instances, and managed AI/ML services."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Pros:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Scalability:"})," Easily scale computational resources up or down as needed, without significant upfront hardware investment."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Accessibility:"})," Access powerful GPUs and specialized hardware from anywhere with an internet connection."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Managed Services:"})," Benefit from managed services for databases, AI/ML platforms (e.g., AWS SageMaker, Google Cloud AI Platform, Azure Machine Learning), and MLOps tools."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Cost-Effective (for bursts):"})," Pay-as-you-go model can be cost-effective for intermittent workloads or specific training jobs."]}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Cons:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Latency:"})," Increased latency for real-time robot control and sensor data processing, especially for physical robots located far from data centers."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Cost (for continuous use):"})," Can become expensive for continuous, high-performance workloads, particularly with dedicated GPU instances."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Data Transfer:"})," Transferring large datasets between on-premise sensors/robots and cloud storage can be slow and costly."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Security:"})," Requires careful consideration of data privacy and security protocols when transmitting sensitive robotics data to the cloud."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"on-premise-solutions",children:"On-Premise Solutions"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Description:"})," Utilizing local hardware and infrastructure for all computational needs, including workstations, server racks, and local robot labs."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Pros:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Low Latency:"})," Ideal for real-time control of physical robots, where immediate feedback and minimal delay are crucial."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Data Privacy:"})," Full control over data security and privacy, as all data remains within the local network."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Cost-Effective (for continuous use):"})," Lower operational costs over the long term for continuous, high-performance computing after the initial hardware investment."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Customization:"})," Greater flexibility to customize hardware and software environments to specific research or project needs."]}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Cons:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Upfront Cost:"})," Requires significant initial investment in hardware (CPUs, GPUs, servers, networking)."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Maintenance:"})," Responsibility for hardware maintenance, upgrades, and power consumption."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Scalability:"})," Scaling resources can be challenging and expensive, often requiring new hardware purchases."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Accessibility:"})," Limited to local access, unless remote access solutions are implemented."]}),"\n"]}),"\n"]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(d,{...e})}):d(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>t,x:()=>a});var s=i(6540);const o={},r=s.createContext(o);function t(e){const n=s.useContext(r);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:t(e.components),s.createElement(r.Provider,{value:n},e.children)}}}]);